{
  "name": "ai-code-security-study",
  "version": "1.0.0",
  "description": "Security evaluation of code generated by large language models",
  "main": "index.js",
  "scripts": {
    "lint": "eslint generated_code/**/*.js",
    "lint:chatgpt": "eslint generated_code/chatgpt/*.js --format json > analysis/eslint_results/chatgpt.json",
    "lint:claude": "eslint generated_code/claude/*.js --format json > analysis/eslint_results/claude.json",
    "lint:gemini": "eslint generated_code/gemini/*.js --format json > analysis/eslint_results/gemini.json",
    "lint:deepseek": "eslint generated_code/deepseek/*.js --format json > analysis/eslint_results/deepseek.json",
    "lint:grok": "eslint generated_code/grok/*.js --format json > analysis/eslint_results/grok.json",
    "lint:all": "npm run lint:chatgpt && npm run lint:claude && npm run lint:gemini && npm run lint:deepseek && npm run lint:grok"
  },
  "keywords": [
    "security",
    "AI",
    "LLM",
    "code-generation",
    "vulnerability",
    "research"
  ],
  "author": "Malak H. I. Mansour",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/malakh727/ai-code-security-study.git"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.1",
    "eslint": "^8.57.1",
    "eslint-plugin-security": "^2.1.0",
    "globals": "^16.5.0"
  }
}
